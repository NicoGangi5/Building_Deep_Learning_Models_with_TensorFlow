{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecurrentNetworksAndLSTMInDeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsaMvxuTxvpW5LBA4i11PJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoGangi5/Building_Deep_Learning_Models_with_TensorFlow/blob/main/RecurrentNetworksAndLSTMInDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5O5QDl1JakQ"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z_AgewOLsVl",
        "outputId": "b1f14d0b-bad7-4101-f3bc-5e90e74e0e7f"
      },
      "source": [
        "!mkdir data\n",
        "!mkdir data/ptb\n",
        "!wget -q -O data/ptb/reader.py https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0120EN-SkillsNetwork/labs/Week3/data/ptb/reader.py\n",
        "!cp data/ptb/reader.py . "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘data/ptb’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJamaYqDLvek"
      },
      "source": [
        "import reader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfNH_B5fL7LB"
      },
      "source": [
        "# Building the LSTM model for Language Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK5SDaMqL4tg",
        "outputId": "454662d7-cbd7-465d-c534-cda1fd98ab92"
      },
      "source": [
        "!wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz \n",
        "!tar xzf simple-examples.tgz -C data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-11 19:03:31--  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
            "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 2001:67c:1220:809::93e5:917\n",
            "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34869662 (33M) [application/x-gtar]\n",
            "Saving to: ‘simple-examples.tgz’\n",
            "\n",
            "simple-examples.tgz 100%[===================>]  33.25M  2.99MB/s    in 14s     \n",
            "\n",
            "2020-12-11 19:03:46 (2.43 MB/s) - ‘simple-examples.tgz’ saved [34869662/34869662]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chUElMIcMGPy"
      },
      "source": [
        "#Initial weight scale\n",
        "init_scale = 0.1\n",
        "#Initial learning rate\n",
        "learning_rate = 1.0\n",
        "#Maximum permissible norm for the gradient (For gradient clipping -- another measure against Exploding Gradients)\n",
        "max_grad_norm = 5\n",
        "#The number of layers in our model\n",
        "num_layers = 2\n",
        "#The total number of recurrence steps, also known as the number of layers when our RNN is \"unfolded\"\n",
        "num_steps = 20\n",
        "#The number of processing units (neurons) in the hidden layers\n",
        "hidden_size_l1 = 256\n",
        "hidden_size_l2 = 128\n",
        "#The maximum number of epochs trained with the initial learning rate\n",
        "max_epoch_decay_lr = 4\n",
        "#The total number of epochs in training\n",
        "max_epoch = 15\n",
        "#The probability for keeping data in the Dropout Layer (This is an optimization, but is outside our scope for this notebook!)\n",
        "#At 1, we ignore the Dropout Layer wrapping.\n",
        "keep_prob = 1\n",
        "#The decay for the learning rate\n",
        "decay = 0.5\n",
        "#The size for each batch of data\n",
        "batch_size = 30\n",
        "#The size of our vocabulary\n",
        "vocab_size = 10000\n",
        "embeding_vector_size= 200\n",
        "#Training flag to separate training from testing\n",
        "is_training = 1\n",
        "#Data directory for our dataset\n",
        "data_dir = \"data/simple-examples/data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YYR2HC3Mbgt"
      },
      "source": [
        "# Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEowXjf5McSF"
      },
      "source": [
        "# Reads the data and separates it into training data, validation data and testing data\n",
        "raw_data = reader.ptb_raw_data(data_dir)\n",
        "train_data, valid_data, test_data, vocab, word_to_id = raw_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_igrY4slNllk",
        "outputId": "7d041af3-9654-447f-bcc1-5e4871c3df46"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "929589"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkaS6y4jNmnr",
        "outputId": "c277ed77-523a-4472-c65b-e3c731a4567a"
      },
      "source": [
        "def id_to_word(id_list):\n",
        "    line = []\n",
        "    for w in id_list:\n",
        "        for word, wid in word_to_id.items():\n",
        "            if wid == w:\n",
        "                line.append(word)\n",
        "    return line            \n",
        "                \n",
        "\n",
        "print(id_to_word(train_data[0:100]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', 'N', '<eos>', 'mr.', '<unk>', 'is', 'chairman', 'of', '<unk>', 'n.v.', 'the', 'dutch', 'publishing', 'group', '<eos>', 'rudolph', '<unk>', 'N', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '<eos>', 'a', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyyU9EagNpKc"
      },
      "source": [
        "itera = reader.ptb_iterator(train_data, batch_size, num_steps)\n",
        "first_touple = itera.__next__()\n",
        "_input_data = first_touple[0]\n",
        "_targets = first_touple[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGH_2zMlNrWW",
        "outputId": "696810b4-6181-4159-fa0c-0ae7b5f8a348"
      },
      "source": [
        "_input_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHNDP9n_Nt17",
        "outputId": "f720b9ed-f1d2-4e0b-a2cf-e7bf0a73632d"
      },
      "source": [
        "_targets.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqutmPfDNxJR",
        "outputId": "6e09979c-dba3-4d52-f4de-b93de44dd4f0"
      },
      "source": [
        "_input_data[0:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984,\n",
              "        9986, 9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995],\n",
              "       [2654,    6,  334, 2886,    4,    1,  233,  711,  834,   11,  130,\n",
              "         123,    7,  514,    2,   63,   10,  514,    8,  605],\n",
              "       [   0, 1071,    4,    0,  185,   24,  368,   20,   31, 3109,  954,\n",
              "          12,    3,   21,    2, 2915,    2,   12,    3,   21]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MVJxPYXN0ZA",
        "outputId": "b32a6439-0438-4d0b-8abd-5e1a675c1f22"
      },
      "source": [
        "print(id_to_word(_input_data[0,:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIAh8IsYN54J"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFcfv6x1N7bZ"
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(vocab_size, embeding_vector_size,batch_input_shape=(batch_size, num_steps),trainable=True,name=\"embedding_vocab\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xhixHBuONhf",
        "outputId": "18597f7c-40f6-472b-e8ff-bf68f9a98997"
      },
      "source": [
        "# Define where to get the data for our embeddings from\n",
        "inputs = embedding_layer(_input_data)\n",
        "inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30, 20, 200), dtype=float32, numpy=\n",
              "array([[[-0.03470422,  0.04146106, -0.0297532 , ...,  0.01125786,\n",
              "          0.04887327,  0.02209339],\n",
              "        [ 0.0120829 , -0.00110837,  0.00761901, ..., -0.021329  ,\n",
              "         -0.03507759, -0.00708295],\n",
              "        [-0.00756492, -0.02396212,  0.03685098, ...,  0.02290315,\n",
              "         -0.04576325,  0.04717282],\n",
              "        ...,\n",
              "        [-0.02922853,  0.04947071,  0.01766041, ..., -0.01381894,\n",
              "         -0.00383085, -0.02138679],\n",
              "        [ 0.01283851, -0.02183471, -0.01635564, ..., -0.01462068,\n",
              "          0.04689045, -0.02046909],\n",
              "        [-0.01669873, -0.03602555,  0.0236362 , ..., -0.04913708,\n",
              "         -0.00452728, -0.04101343]],\n",
              "\n",
              "       [[ 0.03194896, -0.02194725, -0.00658724, ..., -0.04316182,\n",
              "          0.03220231,  0.00898095],\n",
              "        [ 0.02773329,  0.0083137 ,  0.00162787, ..., -0.00441587,\n",
              "          0.03186499, -0.00684167],\n",
              "        [-0.03177078, -0.00841136, -0.00976527, ...,  0.02787569,\n",
              "         -0.04511375, -0.00850808],\n",
              "        ...,\n",
              "        [-0.02372775,  0.02818649, -0.04176309, ..., -0.02744608,\n",
              "          0.03101883,  0.02523333],\n",
              "        [-0.02126346,  0.02758672,  0.01862742, ..., -0.0474376 ,\n",
              "          0.03974367, -0.00855398],\n",
              "        [-0.04465323, -0.01621076,  0.04942603, ...,  0.00695818,\n",
              "          0.02704687, -0.03273664]],\n",
              "\n",
              "       [[ 0.00776812, -0.04849699,  0.03354425, ...,  0.026182  ,\n",
              "          0.03158302, -0.0311562 ],\n",
              "        [ 0.02994852, -0.01470432,  0.03989576, ...,  0.028855  ,\n",
              "          0.04072037,  0.03127128],\n",
              "        [-0.02767783, -0.02206333, -0.02901629, ..., -0.00675675,\n",
              "          0.02647606, -0.01317873],\n",
              "        ...,\n",
              "        [ 0.04841715,  0.03949893,  0.04800362, ..., -0.04195739,\n",
              "          0.03617379, -0.02956475],\n",
              "        [-0.01060335, -0.01422403, -0.04377639, ...,  0.01868529,\n",
              "          0.01960516,  0.03415246],\n",
              "        [ 0.01524714,  0.00743781,  0.04942269, ...,  0.01455948,\n",
              "         -0.00817024,  0.03293948]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.02691897, -0.00792023, -0.04723265, ..., -0.0196178 ,\n",
              "          0.01675595,  0.03649967],\n",
              "        [ 0.03199429,  0.0206582 ,  0.04149054, ...,  0.02475527,\n",
              "          0.04527784,  0.04284837],\n",
              "        [ 0.01565808, -0.01168365, -0.02661369, ...,  0.01684279,\n",
              "          0.03531051, -0.03334029],\n",
              "        ...,\n",
              "        [-0.02922335,  0.04565706,  0.01423849, ..., -0.03604726,\n",
              "         -0.02403704,  0.0226177 ],\n",
              "        [ 0.02879215,  0.04207439,  0.02731571, ..., -0.00807086,\n",
              "         -0.03775771, -0.03118799],\n",
              "        [-0.00084852,  0.04938142,  0.04709692, ..., -0.03865965,\n",
              "         -0.03067617,  0.02332864]],\n",
              "\n",
              "       [[ 0.0361895 ,  0.01493641, -0.04575771, ...,  0.04292517,\n",
              "         -0.00609915,  0.0482537 ],\n",
              "        [-0.03373776,  0.03071345, -0.04759296, ..., -0.01153513,\n",
              "          0.04044006,  0.02489943],\n",
              "        [-0.02767783, -0.02206333, -0.02901629, ..., -0.00675675,\n",
              "          0.02647606, -0.01317873],\n",
              "        ...,\n",
              "        [-0.04233373, -0.04484008, -0.0046716 , ..., -0.01999555,\n",
              "         -0.02829456,  0.03530079],\n",
              "        [ 0.02773329,  0.0083137 ,  0.00162787, ..., -0.00441587,\n",
              "          0.03186499, -0.00684167],\n",
              "        [ 0.03831998,  0.03810659,  0.02679319, ...,  0.00414101,\n",
              "          0.02403499,  0.00410994]],\n",
              "\n",
              "       [[-0.0357461 , -0.0214417 , -0.01476287, ...,  0.04196509,\n",
              "          0.03193391,  0.02121408],\n",
              "        [ 0.0351552 , -0.02554318,  0.04669252, ...,  0.03033124,\n",
              "         -0.04490448,  0.02272752],\n",
              "        [-0.04796655, -0.04272121,  0.04613904, ...,  0.0265861 ,\n",
              "          0.04829392, -0.01109181],\n",
              "        ...,\n",
              "        [ 0.02486921,  0.02588322, -0.03744302, ...,  0.02785739,\n",
              "         -0.00329248, -0.00217469],\n",
              "        [ 0.03151165,  0.01947372, -0.00910044, ...,  0.00025344,\n",
              "          0.03522934,  0.01789086],\n",
              "        [-0.01054416,  0.00061532,  0.04629986, ..., -0.01455861,\n",
              "          0.04403705,  0.00452939]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP_UwgirOOX-",
        "outputId": "92e538b6-be35-4127-8d65-a42f0e0a83d7"
      },
      "source": [
        "# Define where to get the data for our embeddings from\n",
        "inputs = embedding_layer(_input_data)\n",
        "inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30, 20, 200), dtype=float32, numpy=\n",
              "array([[[-0.03470422,  0.04146106, -0.0297532 , ...,  0.01125786,\n",
              "          0.04887327,  0.02209339],\n",
              "        [ 0.0120829 , -0.00110837,  0.00761901, ..., -0.021329  ,\n",
              "         -0.03507759, -0.00708295],\n",
              "        [-0.00756492, -0.02396212,  0.03685098, ...,  0.02290315,\n",
              "         -0.04576325,  0.04717282],\n",
              "        ...,\n",
              "        [-0.02922853,  0.04947071,  0.01766041, ..., -0.01381894,\n",
              "         -0.00383085, -0.02138679],\n",
              "        [ 0.01283851, -0.02183471, -0.01635564, ..., -0.01462068,\n",
              "          0.04689045, -0.02046909],\n",
              "        [-0.01669873, -0.03602555,  0.0236362 , ..., -0.04913708,\n",
              "         -0.00452728, -0.04101343]],\n",
              "\n",
              "       [[ 0.03194896, -0.02194725, -0.00658724, ..., -0.04316182,\n",
              "          0.03220231,  0.00898095],\n",
              "        [ 0.02773329,  0.0083137 ,  0.00162787, ..., -0.00441587,\n",
              "          0.03186499, -0.00684167],\n",
              "        [-0.03177078, -0.00841136, -0.00976527, ...,  0.02787569,\n",
              "         -0.04511375, -0.00850808],\n",
              "        ...,\n",
              "        [-0.02372775,  0.02818649, -0.04176309, ..., -0.02744608,\n",
              "          0.03101883,  0.02523333],\n",
              "        [-0.02126346,  0.02758672,  0.01862742, ..., -0.0474376 ,\n",
              "          0.03974367, -0.00855398],\n",
              "        [-0.04465323, -0.01621076,  0.04942603, ...,  0.00695818,\n",
              "          0.02704687, -0.03273664]],\n",
              "\n",
              "       [[ 0.00776812, -0.04849699,  0.03354425, ...,  0.026182  ,\n",
              "          0.03158302, -0.0311562 ],\n",
              "        [ 0.02994852, -0.01470432,  0.03989576, ...,  0.028855  ,\n",
              "          0.04072037,  0.03127128],\n",
              "        [-0.02767783, -0.02206333, -0.02901629, ..., -0.00675675,\n",
              "          0.02647606, -0.01317873],\n",
              "        ...,\n",
              "        [ 0.04841715,  0.03949893,  0.04800362, ..., -0.04195739,\n",
              "          0.03617379, -0.02956475],\n",
              "        [-0.01060335, -0.01422403, -0.04377639, ...,  0.01868529,\n",
              "          0.01960516,  0.03415246],\n",
              "        [ 0.01524714,  0.00743781,  0.04942269, ...,  0.01455948,\n",
              "         -0.00817024,  0.03293948]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.02691897, -0.00792023, -0.04723265, ..., -0.0196178 ,\n",
              "          0.01675595,  0.03649967],\n",
              "        [ 0.03199429,  0.0206582 ,  0.04149054, ...,  0.02475527,\n",
              "          0.04527784,  0.04284837],\n",
              "        [ 0.01565808, -0.01168365, -0.02661369, ...,  0.01684279,\n",
              "          0.03531051, -0.03334029],\n",
              "        ...,\n",
              "        [-0.02922335,  0.04565706,  0.01423849, ..., -0.03604726,\n",
              "         -0.02403704,  0.0226177 ],\n",
              "        [ 0.02879215,  0.04207439,  0.02731571, ..., -0.00807086,\n",
              "         -0.03775771, -0.03118799],\n",
              "        [-0.00084852,  0.04938142,  0.04709692, ..., -0.03865965,\n",
              "         -0.03067617,  0.02332864]],\n",
              "\n",
              "       [[ 0.0361895 ,  0.01493641, -0.04575771, ...,  0.04292517,\n",
              "         -0.00609915,  0.0482537 ],\n",
              "        [-0.03373776,  0.03071345, -0.04759296, ..., -0.01153513,\n",
              "          0.04044006,  0.02489943],\n",
              "        [-0.02767783, -0.02206333, -0.02901629, ..., -0.00675675,\n",
              "          0.02647606, -0.01317873],\n",
              "        ...,\n",
              "        [-0.04233373, -0.04484008, -0.0046716 , ..., -0.01999555,\n",
              "         -0.02829456,  0.03530079],\n",
              "        [ 0.02773329,  0.0083137 ,  0.00162787, ..., -0.00441587,\n",
              "          0.03186499, -0.00684167],\n",
              "        [ 0.03831998,  0.03810659,  0.02679319, ...,  0.00414101,\n",
              "          0.02403499,  0.00410994]],\n",
              "\n",
              "       [[-0.0357461 , -0.0214417 , -0.01476287, ...,  0.04196509,\n",
              "          0.03193391,  0.02121408],\n",
              "        [ 0.0351552 , -0.02554318,  0.04669252, ...,  0.03033124,\n",
              "         -0.04490448,  0.02272752],\n",
              "        [-0.04796655, -0.04272121,  0.04613904, ...,  0.0265861 ,\n",
              "          0.04829392, -0.01109181],\n",
              "        ...,\n",
              "        [ 0.02486921,  0.02588322, -0.03744302, ...,  0.02785739,\n",
              "         -0.00329248, -0.00217469],\n",
              "        [ 0.03151165,  0.01947372, -0.00910044, ...,  0.00025344,\n",
              "          0.03522934,  0.01789086],\n",
              "        [-0.01054416,  0.00061532,  0.04629986, ..., -0.01455861,\n",
              "          0.04403705,  0.00452939]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59q9ZSpmOSNH"
      },
      "source": [
        "# Constructing Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx3qnk7rOUNn"
      },
      "source": [
        "lstm_cell_l1 = tf.keras.layers.LSTMCell(hidden_size_l1)\n",
        "lstm_cell_l2 = tf.keras.layers.LSTMCell(hidden_size_l2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwWjqRceOUgp"
      },
      "source": [
        "stacked_lstm = tf.keras.layers.StackedRNNCells([lstm_cell_l1, lstm_cell_l2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0xLBdbjOVxf"
      },
      "source": [
        "layer  =  tf.keras.layers.RNN(stacked_lstm,[batch_size, num_steps],return_state=False,stateful=True,trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfi1q9o9OY2H"
      },
      "source": [
        "*_initial_state*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4szK3LGOXKy"
      },
      "source": [
        "init_state = tf.Variable(tf.zeros([batch_size,embeding_vector_size]),trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2XI-njAOfhv"
      },
      "source": [
        "layer.inital_state = init_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKWnDkGoOg1I",
        "outputId": "e245fc5a-0417-4b4e-8b05-97d7e4ef4f8a"
      },
      "source": [
        "layer.inital_state"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(30, 200) dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nrGjn_BOjeA"
      },
      "source": [
        "outputs = layer(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMwUPbpsOkVF",
        "outputId": "1f99c7a4-4c1b-49a2-d56f-f8a73e6af28d"
      },
      "source": [
        "outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30, 20, 128), dtype=float32, numpy=\n",
              "array([[[ 1.2238341e-03,  1.1477596e-03, -1.1290435e-03, ...,\n",
              "          4.9584854e-05,  1.1587004e-03,  9.0458069e-04],\n",
              "        [ 1.0300616e-03,  2.0990944e-03,  4.5994157e-06, ...,\n",
              "          6.1789498e-04,  2.4480091e-03,  1.6740604e-03],\n",
              "        [ 4.9890945e-04,  3.2567137e-03,  1.4662925e-04, ...,\n",
              "          2.3462274e-04,  2.1329196e-03,  1.8225710e-03],\n",
              "        ...,\n",
              "        [-3.5142207e-03, -5.0677685e-03, -6.8256077e-03, ...,\n",
              "         -6.1697378e-03,  6.6987243e-03,  4.7551180e-04],\n",
              "        [-3.1958537e-03, -5.1678289e-03, -8.9228461e-03, ...,\n",
              "         -7.4503357e-03,  8.8124685e-03,  4.5684428e-04],\n",
              "        [-2.4932197e-03, -3.3270491e-03, -8.3657783e-03, ...,\n",
              "         -7.4896696e-03,  1.0019653e-02,  7.6640816e-04]],\n",
              "\n",
              "       [[-7.2063856e-05,  7.0347532e-04,  8.3370350e-04, ...,\n",
              "          1.5397972e-03,  6.2558422e-04,  7.5539625e-05],\n",
              "        [ 8.7779248e-04,  9.9938094e-05,  1.2810752e-03, ...,\n",
              "          2.1919790e-03,  1.0419862e-03,  7.4968720e-04],\n",
              "        [ 1.5161529e-03, -4.3786033e-05,  1.4512686e-03, ...,\n",
              "          2.2380115e-03,  7.4965029e-04,  2.3735953e-04],\n",
              "        ...,\n",
              "        [ 1.2332016e-03,  1.8019085e-03,  5.6025051e-03, ...,\n",
              "         -1.2150202e-03, -6.1135767e-03,  2.3589015e-03],\n",
              "        [ 1.0746820e-03,  1.3338270e-03,  5.2578789e-03, ...,\n",
              "         -1.3601849e-03, -7.2210161e-03,  2.5064705e-03],\n",
              "        [ 2.0364822e-04,  7.1221881e-04,  5.9974245e-03, ...,\n",
              "         -6.6726212e-04, -6.3904356e-03,  1.9634862e-03]],\n",
              "\n",
              "       [[ 1.6135683e-03, -8.1570842e-04, -1.1431988e-03, ...,\n",
              "         -6.0950656e-04, -2.5441704e-04,  2.0101829e-03],\n",
              "        [ 1.6113977e-03, -3.4604428e-04, -3.3265913e-03, ...,\n",
              "         -2.5225634e-04,  6.5924483e-04,  2.7288180e-03],\n",
              "        [ 7.3658489e-04,  4.1319348e-04, -5.2088690e-03, ...,\n",
              "         -1.4917320e-04,  2.4403897e-03,  3.1516431e-03],\n",
              "        ...,\n",
              "        [-2.0014357e-03,  2.5387220e-03,  2.2691480e-04, ...,\n",
              "          2.1487693e-03, -2.9726268e-03,  4.5084516e-03],\n",
              "        [-1.7759389e-03,  2.3791275e-03,  2.2594591e-03, ...,\n",
              "          2.0126798e-03, -3.5929705e-03,  5.2082865e-03],\n",
              "        [-2.1196334e-03,  2.2377009e-03,  2.7369922e-03, ...,\n",
              "          2.1074102e-03, -3.4688187e-03,  6.5379087e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 5.7860086e-04, -1.1505873e-03, -2.3586160e-04, ...,\n",
              "         -5.8213738e-04, -2.8555503e-04,  5.3310639e-04],\n",
              "        [ 4.4058434e-05, -1.5352933e-03, -6.8376184e-04, ...,\n",
              "         -1.7901339e-03, -8.7496842e-04,  1.5236672e-03],\n",
              "        [-5.2155135e-04, -4.2305170e-03, -1.9723171e-05, ...,\n",
              "         -1.9007146e-03, -9.9624263e-04,  2.1475491e-03],\n",
              "        ...,\n",
              "        [-5.7615219e-03, -1.3640253e-03,  4.2412402e-03, ...,\n",
              "         -3.4284161e-03,  2.5550057e-03, -3.7411170e-04],\n",
              "        [-5.0128931e-03, -1.1279158e-03,  3.8064998e-03, ...,\n",
              "         -3.9518056e-03,  1.5917914e-03, -1.5280118e-04],\n",
              "        [-4.7008167e-03, -1.5196418e-03,  4.6819430e-03, ...,\n",
              "         -4.1719782e-03,  1.6352466e-03, -2.2459789e-03]],\n",
              "\n",
              "       [[ 4.0475381e-04, -1.5092477e-03, -4.2254740e-04, ...,\n",
              "          5.5530161e-04, -1.2340862e-03, -1.5329437e-04],\n",
              "        [ 7.8258989e-04, -2.7494654e-03,  6.4152562e-05, ...,\n",
              "          2.5453744e-03, -3.9444910e-03,  4.4188724e-04],\n",
              "        [ 8.5300402e-05, -2.9463512e-03, -8.6294283e-04, ...,\n",
              "          3.0671707e-03, -4.3764818e-03,  7.0375437e-04],\n",
              "        ...,\n",
              "        [-2.3767338e-03, -3.6399171e-03,  9.5121679e-04, ...,\n",
              "          2.4331238e-03, -2.8687599e-03, -2.3477871e-03],\n",
              "        [-2.0987876e-03, -4.6000490e-03,  1.3061856e-03, ...,\n",
              "          2.3337582e-03, -2.5374026e-03, -1.7715766e-03],\n",
              "        [-1.5409548e-03, -4.6416479e-03,  5.3910963e-04, ...,\n",
              "          1.8524156e-03, -3.6481551e-03, -1.3979395e-03]],\n",
              "\n",
              "       [[-4.1342789e-04, -9.4442721e-04,  2.0877749e-04, ...,\n",
              "         -1.6107745e-03,  7.6828268e-04,  8.6053973e-04],\n",
              "        [-1.3911950e-03, -1.1706207e-03,  4.8426987e-04, ...,\n",
              "         -1.6923262e-03,  4.9947290e-04, -1.7083484e-04],\n",
              "        [-3.0315644e-03, -1.1144426e-03,  1.8155863e-05, ...,\n",
              "         -2.1686028e-03,  1.2646449e-03, -1.4979017e-03],\n",
              "        ...,\n",
              "        [ 5.4443587e-04, -9.9934684e-04, -2.9001434e-03, ...,\n",
              "          5.7314266e-03, -4.7920523e-03, -4.6911985e-03],\n",
              "        [-1.2826281e-04, -4.0771096e-04, -3.7416890e-03, ...,\n",
              "          4.2576287e-03, -4.7284965e-03, -4.5016170e-03],\n",
              "        [ 5.4564374e-04,  9.1200863e-04, -3.0124732e-03, ...,\n",
              "          3.2128377e-03, -3.9687068e-03, -3.9049864e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTPxlXJ3Om38"
      },
      "source": [
        "## Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT5Z6Cq0Onfv"
      },
      "source": [
        "dense = tf.keras.layers.Dense(vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUs7v4SaOp8a"
      },
      "source": [
        "logits_outputs  = dense(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3qVcNVSOuBT",
        "outputId": "eb8c9732-3180-40a4-ac26-4439be615ef5"
      },
      "source": [
        "print(\"shape of the output from dense layer: \", logits_outputs.shape) #(batch_size, sequence_length, vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of the output from dense layer:  (30, 20, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VcFh5TpOwCJ"
      },
      "source": [
        "# Activation layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwXCSYyNOxn4"
      },
      "source": [
        "activation = tf.keras.layers.Activation('softmax')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhTxRAR_OylK"
      },
      "source": [
        "output_words_prob = activation(logits_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSH-vJY1O0Sw",
        "outputId": "79f37670-161e-4ff3-84a8-e6415ac364dd"
      },
      "source": [
        "print(\"shape of the output from the activation layer: \", output_words_prob.shape) #(batch_size, sequence_length, vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of the output from the activation layer:  (30, 20, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1_LBSAMO1wl",
        "outputId": "bb00ae0b-322f-41e0-94dc-a1b36c48776b"
      },
      "source": [
        "print(\"The probability of observing words in t=0 to t=20\", output_words_prob[0,0:num_steps])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The probability of observing words in t=0 to t=20 tf.Tensor(\n",
            "[[9.99981130e-05 1.00021389e-04 9.99983968e-05 ... 1.00013887e-04\n",
            "  1.00011486e-04 1.00013422e-04]\n",
            " [9.99760887e-05 1.00042576e-04 1.00007572e-04 ... 1.00018158e-04\n",
            "  1.00021694e-04 1.00002209e-04]\n",
            " [9.99797048e-05 1.00044599e-04 1.00010184e-04 ... 1.00031801e-04\n",
            "  1.00009536e-04 9.99668337e-05]\n",
            " ...\n",
            " [9.99340482e-05 9.99844196e-05 1.00004647e-04 ... 9.99402182e-05\n",
            "  9.99952681e-05 1.00037767e-04]\n",
            " [9.99275653e-05 1.00018886e-04 1.00000463e-04 ... 9.99706390e-05\n",
            "  9.99708864e-05 1.00048099e-04]\n",
            " [9.99247495e-05 1.00047546e-04 1.00029123e-04 ... 9.99819240e-05\n",
            "  9.99589902e-05 1.00047633e-04]], shape=(20, 10000), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEVQgtwdO4CX"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg-bCTbAO3K9",
        "outputId": "c14879a9-3d47-4348-99c3-39aea46f7c19"
      },
      "source": [
        "np.argmax(output_words_prob[0,0:num_steps], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6042,  551, 1572, 7799, 7799, 8295, 8295, 6017, 7368, 7368, 9098,\n",
              "       9098, 9098, 9243, 3036, 3036, 3036, 3036, 4846, 6294])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0Iou261O7pL",
        "outputId": "cf4a78ca-d884-44c8-d49c-f67e5ae382c2"
      },
      "source": [
        "_targets[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984, 9986,\n",
              "       9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995, 9996], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3ff1uuRO-Y8"
      },
      "source": [
        "*Objetive function*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA3PUkvJPBm1"
      },
      "source": [
        "def crossentropy(y_true, y_pred):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It0vkg38PDxn"
      },
      "source": [
        "loss  = crossentropy(_targets, output_words_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsYnQpAjPFH2",
        "outputId": "6140fc10-22c7-4c8f-9e45-816ae64a67a9"
      },
      "source": [
        "loss[0,:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([9.21044 , 9.210327, 9.209923, 9.210556, 9.21046 , 9.209729,\n",
              "       9.210798, 9.210621, 9.210139, 9.210799], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6_Ou-YZPG2l",
        "outputId": "16beb2a4-c759-4a2c-b06d-a1b64413d897"
      },
      "source": [
        "cost = tf.reduce_sum(loss / batch_size)\n",
        "cost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=184.20639>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNzaIDfSPHsw"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7xAVx5CPJ-1"
      },
      "source": [
        "*1. Define Optimizer*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn9ovygEPOqQ"
      },
      "source": [
        "# Create a variable for the learning rate\n",
        "lr = tf.Variable(0.0, trainable=False)\n",
        "optimizer = tf.keras.optimizers.SGD(lr=lr, clipnorm=max_grad_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYD06paHPPy6"
      },
      "source": [
        "*2. Assemble layers to build model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LCdXR0APSeA",
        "outputId": "95dc43bb-ba40-4e46-ada7-83db9f674866"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(layer)\n",
        "model.add(dense)\n",
        "model.add(activation)\n",
        "model.compile(loss=crossentropy, optimizer=optimizer)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_vocab (Embedding)  (30, 20, 200)             2000000   \n",
            "_________________________________________________________________\n",
            "rnn (RNN)                    (30, 20, 128)             671088    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (30, 20, 10000)           1290000   \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (30, 20, 10000)           0         \n",
            "=================================================================\n",
            "Total params: 3,961,088\n",
            "Trainable params: 3,955,088\n",
            "Non-trainable params: 6,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piaT-c6wPaUX"
      },
      "source": [
        "*3. Trainable Variables*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLOsajJ_PcUG"
      },
      "source": [
        "# Get all TensorFlow variables marked as \"trainable\" (i.e. all of them except _lr, which we just created)\n",
        "tvars = model.trainable_variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIXj-j_ePfXf",
        "outputId": "2701cb4b-e866-46c6-9d8f-0f2a1700d284"
      },
      "source": [
        "[v.name for v in tvars] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['embedding_vocab/embeddings:0',\n",
              " 'rnn/stacked_rnn_cells/lstm_cell/kernel:0',\n",
              " 'rnn/stacked_rnn_cells/lstm_cell/recurrent_kernel:0',\n",
              " 'rnn/stacked_rnn_cells/lstm_cell/bias:0',\n",
              " 'rnn/stacked_rnn_cells/lstm_cell_1/kernel:0',\n",
              " 'rnn/stacked_rnn_cells/lstm_cell_1/recurrent_kernel:0',\n",
              " 'rnn/stacked_rnn_cells/lstm_cell_1/bias:0',\n",
              " 'dense/kernel:0',\n",
              " 'dense/bias:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01H3hhGcPhxs"
      },
      "source": [
        "*4. Calculate the gradients based on the loss function*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFfmaaeUPjmg"
      },
      "source": [
        "x = tf.constant(1.0)\n",
        "y =  tf.constant(2.0)\n",
        "with tf.GradientTape(persistent=True) as g:\n",
        "    g.watch(x)\n",
        "    g.watch(y)\n",
        "    func_test = 2 * x * x + 3 * x * y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3P7AOdWPmVZ",
        "outputId": "248fce87-4edf-44ac-eadf-032cbea36eed"
      },
      "source": [
        "var_grad = g.gradient(func_test, x) # Will compute to 10.0\n",
        "print(var_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(10.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLqmaGAcPm1t",
        "outputId": "027ce63f-529a-4e7a-e833-d372211af061"
      },
      "source": [
        "var_grad = g.gradient(func_test, y) # Will compute to 3.0\n",
        "print(var_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHxf2xkPPoIW"
      },
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    # Forward pass.\n",
        "    output_words_prob = model(_input_data)\n",
        "    # Loss value for this batch.\n",
        "    loss  = crossentropy(_targets, output_words_prob)\n",
        "    cost = tf.reduce_sum(loss,axis=0) / batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh7chHazPpg7"
      },
      "source": [
        "# Get gradients of loss wrt the trainable variables.\n",
        "grad_t_list = tape.gradient(cost, tvars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0NXfbupPquT",
        "outputId": "e586497b-c23f-44a6-af0f-f04c3ec142a0"
      },
      "source": [
        "print(grad_t_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7fce5715e588>, <tf.Tensor: shape=(200, 1024), dtype=float32, numpy=\n",
            "array([[-4.84338216e-07,  2.80956783e-07, -2.99956810e-07, ...,\n",
            "         3.19761497e-08, -3.22824491e-07, -1.17459535e-08],\n",
            "       [ 1.77794141e-06, -1.36280320e-07, -1.27357453e-07, ...,\n",
            "         1.64011723e-07,  3.42687656e-08,  4.17386161e-07],\n",
            "       [ 2.39908815e-07,  2.51930658e-07, -5.87190016e-07, ...,\n",
            "        -2.07173514e-07, -3.30247644e-07,  2.03384616e-07],\n",
            "       ...,\n",
            "       [-2.96242860e-07, -3.67769246e-07,  1.07804271e-06, ...,\n",
            "         8.28440250e-08, -1.64169990e-07, -4.95853556e-07],\n",
            "       [-3.01611806e-07, -2.30405831e-07,  1.05803656e-06, ...,\n",
            "        -1.04545279e-07, -1.83397418e-07, -4.90317632e-07],\n",
            "       [-6.99878456e-07, -3.63556950e-07, -9.99256855e-08, ...,\n",
            "        -7.14011392e-08,  2.25640051e-07,  8.57263132e-08]], dtype=float32)>, <tf.Tensor: shape=(256, 1024), dtype=float32, numpy=\n",
            "array([[-3.9737643e-08,  2.9265824e-08,  5.3763327e-09, ...,\n",
            "         4.8724949e-08, -4.4655465e-08, -2.2512566e-08],\n",
            "       [-5.8360570e-09,  3.0519629e-08, -2.7960479e-07, ...,\n",
            "        -6.7981240e-08,  1.4220723e-07,  2.8179414e-07],\n",
            "       [-1.1022236e-07,  3.3752737e-08, -1.3693617e-08, ...,\n",
            "         3.1331634e-08,  1.1538831e-07, -4.6582254e-08],\n",
            "       ...,\n",
            "       [ 5.0186195e-08,  3.7974104e-08, -1.5256633e-07, ...,\n",
            "        -5.8667350e-08, -6.0770176e-08,  3.2025099e-07],\n",
            "       [ 6.0198772e-08,  7.4403971e-08,  9.3450744e-08, ...,\n",
            "         8.5727486e-08,  3.7247634e-08, -2.3665939e-07],\n",
            "       [ 4.2871992e-08, -5.5804517e-09,  3.8461714e-08, ...,\n",
            "        -6.6633756e-09, -1.1278596e-08, -3.7038535e-07]], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
            "array([-5.1853094e-06, -2.3923154e-05,  1.9639810e-05, ...,\n",
            "        5.7607276e-06, -2.3568986e-05, -3.8596605e-05], dtype=float32)>, <tf.Tensor: shape=(256, 512), dtype=float32, numpy=\n",
            "array([[ 7.03971992e-09,  4.19658761e-08,  2.58414104e-07, ...,\n",
            "        -3.47637467e-07, -2.39641196e-07, -7.75107480e-08],\n",
            "       [ 2.87063955e-07, -9.35130728e-08, -5.61921496e-08, ...,\n",
            "        -4.45836790e-08, -1.15642834e-07, -1.31624759e-07],\n",
            "       [-3.72201043e-08, -1.50617794e-08,  1.38391712e-07, ...,\n",
            "         1.40425968e-07, -4.03349603e-08,  6.14468405e-08],\n",
            "       ...,\n",
            "       [-1.48840343e-07, -2.68972400e-09, -1.25413166e-07, ...,\n",
            "         6.84299621e-08,  6.07229609e-08, -5.67378322e-08],\n",
            "       [-3.69730373e-07, -1.11283939e-07,  1.28570150e-07, ...,\n",
            "         4.86374603e-08, -1.94846976e-07,  2.85224615e-07],\n",
            "       [-1.43717131e-07, -1.41579122e-07,  2.76948526e-08, ...,\n",
            "        -7.44147854e-08, -2.11126064e-07,  8.38460252e-08]], dtype=float32)>, <tf.Tensor: shape=(128, 512), dtype=float32, numpy=\n",
            "array([[-4.10683242e-07, -1.28884196e-07,  5.50744801e-08, ...,\n",
            "         1.11516535e-07,  6.10524751e-08,  1.96760467e-07],\n",
            "       [-3.21655591e-10,  5.15895131e-08,  9.91456233e-08, ...,\n",
            "         1.22140298e-09, -7.55479306e-08,  1.75666557e-07],\n",
            "       [ 1.75885297e-08,  9.57435660e-08,  2.15939252e-07, ...,\n",
            "         2.62335060e-08, -1.26929152e-08, -3.55696450e-09],\n",
            "       ...,\n",
            "       [ 1.65337951e-07,  1.21244085e-07, -1.52398272e-07, ...,\n",
            "        -1.32985093e-07, -1.55657787e-07,  4.07210798e-08],\n",
            "       [ 3.19283743e-07, -1.20101902e-07, -2.17705193e-07, ...,\n",
            "        -1.60881285e-07, -2.55907651e-07, -1.92036538e-07],\n",
            "       [-2.77322812e-07, -4.07241458e-08, -1.72635950e-09, ...,\n",
            "         9.61610311e-08,  1.93627272e-07,  5.16233683e-07]], dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
            "array([-5.03187039e-05, -4.90624643e-06,  3.24006469e-05,  1.12622452e-04,\n",
            "       -2.11086899e-05,  1.40107713e-05,  1.18585003e-05, -9.87811291e-08,\n",
            "        1.48420149e-05, -2.82011260e-05,  5.48669868e-06, -3.26710724e-05,\n",
            "       -1.34306702e-05,  4.10885441e-05,  3.36938174e-05,  9.66252901e-06,\n",
            "        8.70633448e-06,  2.41753696e-05, -3.29688919e-05, -3.45906483e-05,\n",
            "       -5.14962921e-05, -2.30827645e-05,  1.13884562e-05,  1.59816555e-05,\n",
            "        1.59376559e-05,  2.18142450e-05,  1.77473230e-05,  2.38919311e-05,\n",
            "        3.15819125e-05, -2.35745192e-05, -1.55910457e-05,  5.71306882e-05,\n",
            "        2.05624729e-05,  2.37117165e-05, -3.87285036e-05, -5.43679271e-05,\n",
            "        1.68663155e-05,  5.24331954e-05, -5.62697369e-06,  3.04434752e-06,\n",
            "       -1.04451910e-05,  2.78273692e-05, -2.14460797e-05, -2.04183234e-05,\n",
            "       -2.37254171e-05,  2.12657433e-05,  1.10143137e-05, -6.10334646e-05,\n",
            "       -4.11587735e-07, -8.21652575e-05, -4.34307622e-05,  5.39211615e-05,\n",
            "        1.30853768e-05,  1.83681404e-05, -7.46042060e-05, -2.27991422e-05,\n",
            "       -9.55451014e-06, -6.53587904e-08, -4.99129783e-05, -4.39020077e-05,\n",
            "       -6.22174048e-06,  1.56249534e-05,  8.75068235e-06, -2.28165409e-05,\n",
            "       -1.47323017e-05, -1.50447931e-05,  3.78803525e-05, -1.26462510e-06,\n",
            "       -2.54159786e-05, -3.52022253e-05,  8.39171571e-06, -6.36668556e-05,\n",
            "       -9.79658398e-06,  1.76160393e-05, -3.50398695e-05, -6.72571987e-05,\n",
            "        2.50813991e-05,  2.08344718e-05,  3.75120544e-06,  1.64988924e-05,\n",
            "       -6.19668572e-06,  1.02131853e-05,  4.54254077e-05,  9.44038547e-05,\n",
            "       -3.73260518e-05, -3.58083344e-05, -5.17345325e-05,  1.54486697e-05,\n",
            "       -2.08752135e-05, -1.15275880e-05, -3.21243606e-05, -6.12230724e-05,\n",
            "        6.70808595e-06,  3.32108721e-05,  1.19441684e-05,  4.28242020e-05,\n",
            "        1.86204397e-06,  1.47747678e-05, -5.16138971e-05,  1.48188628e-05,\n",
            "        1.05844283e-05,  3.26237932e-06,  2.25363747e-05, -4.59909497e-05,\n",
            "        1.37453108e-05, -1.13383459e-04, -1.39555204e-05, -2.64847840e-05,\n",
            "       -2.36013784e-05,  2.20673592e-05, -2.24069190e-05,  1.23361460e-05,\n",
            "       -2.65405306e-05,  5.48858407e-06,  7.27667284e-05, -1.25532461e-06,\n",
            "        2.49569825e-06,  1.48158606e-05,  1.81549876e-05, -1.40046641e-05,\n",
            "       -1.91364070e-05, -2.38776502e-05, -1.86571397e-05,  1.93507822e-05,\n",
            "        1.24757553e-05,  3.05845133e-05,  6.25741086e-06,  3.33096395e-05,\n",
            "       -6.19016282e-05, -2.49920322e-06,  1.46640050e-05,  1.72693544e-04,\n",
            "       -2.22601302e-05,  6.54148607e-07,  1.57662562e-05,  9.08534275e-06,\n",
            "        1.47610972e-05, -3.37598030e-05, -1.27316207e-05, -4.38279676e-05,\n",
            "       -1.18441494e-05,  4.77240283e-05,  3.99954442e-05, -3.56192186e-06,\n",
            "        2.93351513e-05,  4.26285733e-05, -4.43255049e-05, -1.92876905e-05,\n",
            "       -1.02428850e-04, -3.15841389e-05,  4.58618160e-06, -1.23482760e-05,\n",
            "        4.56070957e-05,  3.53058786e-05,  3.28652241e-05,  1.84205583e-05,\n",
            "        4.44620564e-05, -1.14304330e-05, -2.62206850e-05,  8.22025031e-05,\n",
            "        2.30178084e-05,  4.59281800e-05, -6.56536868e-05, -8.32128062e-05,\n",
            "        1.60983327e-05,  7.75638473e-05,  6.57391956e-06,  9.07696403e-07,\n",
            "       -1.06246680e-05,  2.39905385e-05, -2.70454348e-05, -5.75404047e-05,\n",
            "       -4.34432295e-05, -3.85003068e-06,  2.54622810e-05, -8.73443350e-05,\n",
            "       -1.89382135e-05, -9.83616483e-05, -3.83259066e-05,  6.40610961e-05,\n",
            "        5.06292672e-05,  2.22784838e-05, -1.64701443e-04, -2.92869536e-05,\n",
            "       -2.16883491e-05,  1.77276161e-05, -5.94322992e-05, -6.68024222e-05,\n",
            "       -3.58492616e-06, -2.54755560e-06, -2.70184046e-06, -5.88794774e-06,\n",
            "       -1.17426680e-05, -1.80870175e-05,  5.20836547e-05, -2.17184097e-05,\n",
            "       -1.46928132e-05,  8.54730479e-06,  2.25867789e-05, -7.43530909e-05,\n",
            "       -1.68764363e-05,  7.29819385e-06, -3.41779414e-05, -7.62380369e-05,\n",
            "        5.85045345e-05, -7.27915904e-06,  2.07694120e-06,  3.89842862e-05,\n",
            "       -2.83280883e-06,  6.70129157e-06,  5.69413533e-05,  1.28472777e-04,\n",
            "       -7.45524158e-05, -6.72244496e-05, -7.04360937e-05,  3.56107194e-05,\n",
            "       -3.69570043e-05, -3.49013935e-05, -5.73317229e-05, -9.33056144e-05,\n",
            "        5.01192972e-06,  5.95964739e-05,  2.18631794e-05,  5.94299818e-05,\n",
            "        3.46968081e-05,  8.21849699e-06, -5.74200494e-05,  3.34046053e-05,\n",
            "        2.01009643e-05, -1.09922694e-05,  2.45911651e-05, -6.15814497e-05,\n",
            "        1.21140956e-05, -1.23098464e-04, -5.19463065e-05, -4.87376237e-05,\n",
            "       -4.25507969e-05,  3.33554308e-05, -4.07355765e-05,  1.10977089e-05,\n",
            "       -5.38311942e-05, -9.46458385e-07,  1.12127585e-04,  5.24599636e-06,\n",
            "       -3.21046209e-05,  3.07385053e-05,  2.60379602e-06, -6.51698656e-06,\n",
            "       -5.70847697e-05, -2.57752890e-05, -1.85632666e-06,  1.20693066e-05,\n",
            "        4.41941811e-05,  5.27409939e-05, -6.13323664e-06,  4.66659549e-05,\n",
            "       -3.96423414e-02, -5.65765891e-03,  3.84638086e-02, -3.04253791e-02,\n",
            "        2.15299847e-03, -2.71945596e-02,  4.38010879e-02,  2.98216678e-02,\n",
            "       -1.01148095e-02, -3.46007803e-03, -4.75648642e-02, -3.52091063e-03,\n",
            "       -6.27968907e-02,  1.50049888e-02,  2.51152739e-02, -3.52737829e-02,\n",
            "       -2.33082892e-03, -1.02762412e-02,  1.96823943e-02, -2.10875291e-02,\n",
            "        3.02958004e-02, -1.81250870e-02,  2.40815282e-02,  2.27841474e-02,\n",
            "       -3.79781462e-02, -3.31908166e-02,  2.62915753e-02, -2.88937110e-02,\n",
            "       -8.83273594e-03,  5.74676227e-03,  3.22655514e-02, -8.29748064e-03,\n",
            "       -1.64671503e-02,  3.24078500e-02, -5.03643453e-02,  4.34697121e-02,\n",
            "        5.22051007e-03, -3.75282690e-02,  3.25642969e-03,  1.52002368e-03,\n",
            "        4.18215878e-02,  1.62168555e-02, -5.97361010e-04, -1.67422388e-02,\n",
            "        1.56131713e-03, -5.88367358e-02,  2.65284106e-02, -5.17579019e-02,\n",
            "        4.44187671e-02, -2.62404401e-02, -8.57787766e-03, -5.26898168e-03,\n",
            "       -9.70636867e-03,  3.66565189e-04, -5.54528646e-02, -1.35940611e-02,\n",
            "       -3.64447641e-03,  1.22604007e-03, -3.13955992e-02, -5.50706945e-02,\n",
            "        7.52208102e-03,  6.62839040e-04,  3.68181169e-02,  2.26213131e-02,\n",
            "        1.04078930e-02, -1.74411386e-02,  2.97400448e-02,  3.95768397e-02,\n",
            "       -2.42556203e-02,  8.17959663e-03,  2.64215074e-03, -3.59904990e-02,\n",
            "       -5.83446864e-03, -7.17968587e-03,  1.24882329e-02,  4.09964249e-02,\n",
            "        3.70751843e-02, -1.77916810e-02,  5.64424880e-03, -2.84320787e-02,\n",
            "       -1.59197152e-02, -7.33741140e-03,  8.85767303e-03,  4.97913957e-02,\n",
            "        4.00929749e-02, -8.19341466e-03,  4.89902869e-02,  3.32754701e-02,\n",
            "       -1.21586649e-02, -1.26602510e-02,  6.26361668e-02, -4.41546887e-02,\n",
            "        8.40449985e-03,  7.54697388e-03,  7.53984740e-03, -2.88688540e-02,\n",
            "       -5.13420478e-02,  5.09834150e-03, -2.37490796e-02,  3.19544189e-02,\n",
            "        1.60293514e-03, -4.92744260e-02, -6.94755232e-03, -2.03128532e-02,\n",
            "       -2.36845389e-02, -4.91704196e-02, -1.21369567e-02,  7.19241798e-05,\n",
            "        2.29677390e-02,  1.61646865e-04,  1.63336087e-03, -1.01489387e-03,\n",
            "       -3.61233950e-02,  1.51932705e-02, -2.57147942e-04,  9.63311922e-03,\n",
            "       -2.62156855e-02,  2.44358438e-03,  9.70501453e-03, -1.03199901e-02,\n",
            "        3.78324464e-02,  1.38822142e-02,  3.14130518e-03,  1.39819495e-02,\n",
            "       -1.28208278e-02, -1.94533113e-02, -1.78198069e-02,  3.35953720e-02,\n",
            "       -6.10282223e-05, -9.96694689e-06,  2.81926023e-05,  1.32337213e-04,\n",
            "       -3.02834451e-05,  1.34953916e-05,  9.81515768e-06,  1.00539637e-05,\n",
            "        6.85100986e-06, -3.52900242e-05,  9.11824827e-06, -5.04901109e-05,\n",
            "       -1.03115644e-05,  4.50585212e-05,  4.02315745e-05,  6.53286406e-06,\n",
            "        9.60419857e-06,  2.68058629e-05, -4.39894720e-05, -3.47000823e-05,\n",
            "       -5.89484371e-05, -2.84132639e-05,  3.63160598e-06,  1.09541515e-05,\n",
            "        1.32519044e-05,  2.64790233e-05,  1.18186254e-05,  1.92408970e-05,\n",
            "        3.06670336e-05, -2.77847830e-05, -1.60963573e-05,  5.69152835e-05,\n",
            "        2.88019801e-05,  2.65772578e-05, -4.81010284e-05, -6.56315387e-05,\n",
            "        1.83250631e-05,  5.86212336e-05, -2.42181777e-05,  8.19960496e-06,\n",
            "       -5.40298879e-06,  3.48814356e-05, -2.50867306e-05, -3.04958448e-05,\n",
            "       -2.74439626e-05,  1.99605547e-05,  2.00463655e-05, -7.06988576e-05,\n",
            "       -9.07484537e-06, -8.83280736e-05, -5.24317402e-05,  6.13575248e-05,\n",
            "        2.02769024e-05,  1.00116595e-05, -8.56454280e-05, -2.64992050e-05,\n",
            "       -1.54757363e-05,  1.96653286e-06, -5.18316810e-05, -4.39892829e-05,\n",
            "       -1.77941693e-05,  1.78793634e-05,  5.38993390e-06, -2.16622502e-05,\n",
            "       -1.57131835e-05, -3.18722232e-05,  4.28691783e-05, -2.56129829e-06,\n",
            "       -2.24184641e-05, -2.36870183e-05,  1.15592629e-05, -6.59197394e-05,\n",
            "       -3.91865433e-06,  2.57799893e-05, -3.47056812e-05, -7.64509823e-05,\n",
            "        2.46245545e-05,  1.99554215e-05,  8.62864817e-06,  2.29625730e-05,\n",
            "       -1.00494699e-05,  3.97304029e-06,  4.78099537e-05,  9.39053862e-05,\n",
            "       -4.13470079e-05, -4.42040473e-05, -5.61481866e-05,  2.24649884e-05,\n",
            "       -2.33474857e-05, -1.22102228e-05, -4.31570261e-05, -6.96039933e-05,\n",
            "        1.44535416e-05,  3.48848589e-05,  1.55887501e-05,  5.13419218e-05,\n",
            "        8.32287060e-06,  1.89604016e-05, -5.34989231e-05,  1.59974334e-05,\n",
            "        1.67435555e-05, -1.19562196e-06,  2.12854429e-05, -4.94738888e-05,\n",
            "        9.57716293e-06, -1.16132163e-04, -8.41155452e-06, -2.98196701e-05,\n",
            "       -2.73064070e-05,  2.38575631e-05, -3.46984234e-05,  1.30767148e-05,\n",
            "       -3.74936753e-05,  3.84252417e-06,  9.33163028e-05, -5.32031572e-06,\n",
            "       -3.63908202e-06,  1.75336500e-05,  2.17418165e-05, -1.42260305e-05,\n",
            "       -2.44282928e-05, -1.50880114e-05, -2.27969576e-05,  1.62852320e-05,\n",
            "        2.07352059e-05,  3.51844647e-05,  1.13220703e-05,  3.86060747e-05],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(128, 10000), dtype=float32, numpy=\n",
            "array([[-2.2136683e-03, -3.0521704e-03, -1.3861044e-03, ...,\n",
            "         2.2453858e-06,  2.2448494e-06,  2.2464287e-06],\n",
            "       [-1.6136501e-04,  3.1252997e-04,  1.3628686e-03, ...,\n",
            "        -1.3164829e-06, -1.3170138e-06, -1.3186660e-06],\n",
            "       [-5.8814691e-04, -2.7936272e-05, -5.9345912e-04, ...,\n",
            "         8.9910566e-07,  9.0088201e-07,  9.0000401e-07],\n",
            "       ...,\n",
            "       [ 2.0753066e-03,  2.6749447e-03,  1.4803020e-03, ...,\n",
            "        -4.0003738e-06, -3.9988868e-06, -4.0009304e-06],\n",
            "       [ 2.9454096e-03,  3.0650669e-03,  2.5771032e-03, ...,\n",
            "        -5.4220136e-06, -5.4215725e-06, -5.4230468e-06],\n",
            "       [-1.7190180e-03, -3.5369024e-03, -2.0405173e-03, ...,\n",
            "         2.9443706e-06,  2.9430623e-06,  2.9454238e-06]], dtype=float32)>, <tf.Tensor: shape=(10000,), dtype=float32, numpy=\n",
            "array([-0.79799825, -1.0313314 , -1.0313313 , ...,  0.0019997 ,\n",
            "        0.00199942,  0.0020004 ], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae_c_CpYPuUI",
        "outputId": "2a90b116-5a2d-4a1e-d104-9a1c7485adfa"
      },
      "source": [
        "# Define the gradient clipping threshold\n",
        "grads, _ = tf.clip_by_global_norm(grad_t_list, max_grad_norm)\n",
        "grads"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.framework.indexed_slices.IndexedSlices at 0x7fce57168208>,\n",
              " <tf.Tensor: shape=(200, 1024), dtype=float32, numpy=\n",
              " array([[-4.84338216e-07,  2.80956783e-07, -2.99956810e-07, ...,\n",
              "          3.19761497e-08, -3.22824491e-07, -1.17459535e-08],\n",
              "        [ 1.77794141e-06, -1.36280320e-07, -1.27357453e-07, ...,\n",
              "          1.64011723e-07,  3.42687656e-08,  4.17386161e-07],\n",
              "        [ 2.39908815e-07,  2.51930658e-07, -5.87190016e-07, ...,\n",
              "         -2.07173514e-07, -3.30247644e-07,  2.03384616e-07],\n",
              "        ...,\n",
              "        [-2.96242860e-07, -3.67769246e-07,  1.07804271e-06, ...,\n",
              "          8.28440250e-08, -1.64169990e-07, -4.95853556e-07],\n",
              "        [-3.01611806e-07, -2.30405831e-07,  1.05803656e-06, ...,\n",
              "         -1.04545279e-07, -1.83397418e-07, -4.90317632e-07],\n",
              "        [-6.99878456e-07, -3.63556950e-07, -9.99256855e-08, ...,\n",
              "         -7.14011392e-08,  2.25640051e-07,  8.57263132e-08]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(256, 1024), dtype=float32, numpy=\n",
              " array([[-3.9737643e-08,  2.9265824e-08,  5.3763327e-09, ...,\n",
              "          4.8724949e-08, -4.4655465e-08, -2.2512566e-08],\n",
              "        [-5.8360570e-09,  3.0519629e-08, -2.7960479e-07, ...,\n",
              "         -6.7981240e-08,  1.4220723e-07,  2.8179414e-07],\n",
              "        [-1.1022236e-07,  3.3752737e-08, -1.3693617e-08, ...,\n",
              "          3.1331634e-08,  1.1538831e-07, -4.6582254e-08],\n",
              "        ...,\n",
              "        [ 5.0186195e-08,  3.7974104e-08, -1.5256633e-07, ...,\n",
              "         -5.8667350e-08, -6.0770176e-08,  3.2025099e-07],\n",
              "        [ 6.0198772e-08,  7.4403971e-08,  9.3450744e-08, ...,\n",
              "          8.5727486e-08,  3.7247634e-08, -2.3665939e-07],\n",
              "        [ 4.2871992e-08, -5.5804517e-09,  3.8461714e-08, ...,\n",
              "         -6.6633756e-09, -1.1278596e-08, -3.7038535e-07]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
              " array([-5.1853094e-06, -2.3923154e-05,  1.9639810e-05, ...,\n",
              "         5.7607276e-06, -2.3568986e-05, -3.8596605e-05], dtype=float32)>,\n",
              " <tf.Tensor: shape=(256, 512), dtype=float32, numpy=\n",
              " array([[ 7.03971992e-09,  4.19658761e-08,  2.58414104e-07, ...,\n",
              "         -3.47637467e-07, -2.39641196e-07, -7.75107480e-08],\n",
              "        [ 2.87063955e-07, -9.35130728e-08, -5.61921496e-08, ...,\n",
              "         -4.45836790e-08, -1.15642834e-07, -1.31624759e-07],\n",
              "        [-3.72201043e-08, -1.50617794e-08,  1.38391712e-07, ...,\n",
              "          1.40425968e-07, -4.03349603e-08,  6.14468405e-08],\n",
              "        ...,\n",
              "        [-1.48840343e-07, -2.68972400e-09, -1.25413166e-07, ...,\n",
              "          6.84299621e-08,  6.07229609e-08, -5.67378322e-08],\n",
              "        [-3.69730373e-07, -1.11283939e-07,  1.28570150e-07, ...,\n",
              "          4.86374603e-08, -1.94846976e-07,  2.85224615e-07],\n",
              "        [-1.43717131e-07, -1.41579122e-07,  2.76948526e-08, ...,\n",
              "         -7.44147854e-08, -2.11126064e-07,  8.38460252e-08]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(128, 512), dtype=float32, numpy=\n",
              " array([[-4.10683242e-07, -1.28884196e-07,  5.50744801e-08, ...,\n",
              "          1.11516535e-07,  6.10524751e-08,  1.96760467e-07],\n",
              "        [-3.21655591e-10,  5.15895131e-08,  9.91456233e-08, ...,\n",
              "          1.22140298e-09, -7.55479306e-08,  1.75666557e-07],\n",
              "        [ 1.75885297e-08,  9.57435660e-08,  2.15939252e-07, ...,\n",
              "          2.62335060e-08, -1.26929152e-08, -3.55696450e-09],\n",
              "        ...,\n",
              "        [ 1.65337951e-07,  1.21244085e-07, -1.52398272e-07, ...,\n",
              "         -1.32985093e-07, -1.55657787e-07,  4.07210798e-08],\n",
              "        [ 3.19283743e-07, -1.20101902e-07, -2.17705193e-07, ...,\n",
              "         -1.60881285e-07, -2.55907651e-07, -1.92036538e-07],\n",
              "        [-2.77322812e-07, -4.07241458e-08, -1.72635950e-09, ...,\n",
              "          9.61610311e-08,  1.93627272e-07,  5.16233683e-07]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
              " array([-5.03187039e-05, -4.90624643e-06,  3.24006469e-05,  1.12622452e-04,\n",
              "        -2.11086899e-05,  1.40107713e-05,  1.18585003e-05, -9.87811291e-08,\n",
              "         1.48420149e-05, -2.82011260e-05,  5.48669868e-06, -3.26710724e-05,\n",
              "        -1.34306702e-05,  4.10885441e-05,  3.36938174e-05,  9.66252901e-06,\n",
              "         8.70633448e-06,  2.41753696e-05, -3.29688919e-05, -3.45906483e-05,\n",
              "        -5.14962921e-05, -2.30827645e-05,  1.13884562e-05,  1.59816555e-05,\n",
              "         1.59376559e-05,  2.18142450e-05,  1.77473230e-05,  2.38919311e-05,\n",
              "         3.15819125e-05, -2.35745192e-05, -1.55910457e-05,  5.71306882e-05,\n",
              "         2.05624729e-05,  2.37117165e-05, -3.87285036e-05, -5.43679271e-05,\n",
              "         1.68663155e-05,  5.24331954e-05, -5.62697369e-06,  3.04434752e-06,\n",
              "        -1.04451910e-05,  2.78273692e-05, -2.14460797e-05, -2.04183234e-05,\n",
              "        -2.37254171e-05,  2.12657433e-05,  1.10143137e-05, -6.10334646e-05,\n",
              "        -4.11587735e-07, -8.21652575e-05, -4.34307622e-05,  5.39211615e-05,\n",
              "         1.30853768e-05,  1.83681404e-05, -7.46042060e-05, -2.27991422e-05,\n",
              "        -9.55451014e-06, -6.53587904e-08, -4.99129783e-05, -4.39020077e-05,\n",
              "        -6.22174048e-06,  1.56249534e-05,  8.75068235e-06, -2.28165409e-05,\n",
              "        -1.47323017e-05, -1.50447931e-05,  3.78803525e-05, -1.26462510e-06,\n",
              "        -2.54159786e-05, -3.52022253e-05,  8.39171571e-06, -6.36668556e-05,\n",
              "        -9.79658398e-06,  1.76160393e-05, -3.50398695e-05, -6.72571987e-05,\n",
              "         2.50813991e-05,  2.08344718e-05,  3.75120544e-06,  1.64988924e-05,\n",
              "        -6.19668572e-06,  1.02131853e-05,  4.54254077e-05,  9.44038547e-05,\n",
              "        -3.73260518e-05, -3.58083344e-05, -5.17345325e-05,  1.54486697e-05,\n",
              "        -2.08752135e-05, -1.15275880e-05, -3.21243606e-05, -6.12230724e-05,\n",
              "         6.70808595e-06,  3.32108721e-05,  1.19441684e-05,  4.28242020e-05,\n",
              "         1.86204397e-06,  1.47747678e-05, -5.16138971e-05,  1.48188628e-05,\n",
              "         1.05844283e-05,  3.26237932e-06,  2.25363747e-05, -4.59909497e-05,\n",
              "         1.37453108e-05, -1.13383459e-04, -1.39555204e-05, -2.64847840e-05,\n",
              "        -2.36013784e-05,  2.20673592e-05, -2.24069190e-05,  1.23361460e-05,\n",
              "        -2.65405306e-05,  5.48858407e-06,  7.27667284e-05, -1.25532461e-06,\n",
              "         2.49569825e-06,  1.48158606e-05,  1.81549876e-05, -1.40046641e-05,\n",
              "        -1.91364070e-05, -2.38776502e-05, -1.86571397e-05,  1.93507822e-05,\n",
              "         1.24757553e-05,  3.05845133e-05,  6.25741086e-06,  3.33096395e-05,\n",
              "        -6.19016282e-05, -2.49920322e-06,  1.46640050e-05,  1.72693544e-04,\n",
              "        -2.22601302e-05,  6.54148607e-07,  1.57662562e-05,  9.08534275e-06,\n",
              "         1.47610972e-05, -3.37598030e-05, -1.27316207e-05, -4.38279676e-05,\n",
              "        -1.18441494e-05,  4.77240283e-05,  3.99954442e-05, -3.56192186e-06,\n",
              "         2.93351513e-05,  4.26285733e-05, -4.43255049e-05, -1.92876905e-05,\n",
              "        -1.02428850e-04, -3.15841389e-05,  4.58618160e-06, -1.23482760e-05,\n",
              "         4.56070957e-05,  3.53058786e-05,  3.28652241e-05,  1.84205583e-05,\n",
              "         4.44620564e-05, -1.14304330e-05, -2.62206850e-05,  8.22025031e-05,\n",
              "         2.30178084e-05,  4.59281800e-05, -6.56536868e-05, -8.32128062e-05,\n",
              "         1.60983327e-05,  7.75638473e-05,  6.57391956e-06,  9.07696403e-07,\n",
              "        -1.06246680e-05,  2.39905385e-05, -2.70454348e-05, -5.75404047e-05,\n",
              "        -4.34432295e-05, -3.85003068e-06,  2.54622810e-05, -8.73443350e-05,\n",
              "        -1.89382135e-05, -9.83616483e-05, -3.83259066e-05,  6.40610961e-05,\n",
              "         5.06292672e-05,  2.22784838e-05, -1.64701443e-04, -2.92869536e-05,\n",
              "        -2.16883491e-05,  1.77276161e-05, -5.94322992e-05, -6.68024222e-05,\n",
              "        -3.58492616e-06, -2.54755560e-06, -2.70184046e-06, -5.88794774e-06,\n",
              "        -1.17426680e-05, -1.80870175e-05,  5.20836547e-05, -2.17184097e-05,\n",
              "        -1.46928132e-05,  8.54730479e-06,  2.25867789e-05, -7.43530909e-05,\n",
              "        -1.68764363e-05,  7.29819385e-06, -3.41779414e-05, -7.62380369e-05,\n",
              "         5.85045345e-05, -7.27915904e-06,  2.07694120e-06,  3.89842862e-05,\n",
              "        -2.83280883e-06,  6.70129157e-06,  5.69413533e-05,  1.28472777e-04,\n",
              "        -7.45524158e-05, -6.72244496e-05, -7.04360937e-05,  3.56107194e-05,\n",
              "        -3.69570043e-05, -3.49013935e-05, -5.73317229e-05, -9.33056144e-05,\n",
              "         5.01192972e-06,  5.95964739e-05,  2.18631794e-05,  5.94299818e-05,\n",
              "         3.46968081e-05,  8.21849699e-06, -5.74200494e-05,  3.34046053e-05,\n",
              "         2.01009643e-05, -1.09922694e-05,  2.45911651e-05, -6.15814497e-05,\n",
              "         1.21140956e-05, -1.23098464e-04, -5.19463065e-05, -4.87376237e-05,\n",
              "        -4.25507969e-05,  3.33554308e-05, -4.07355765e-05,  1.10977089e-05,\n",
              "        -5.38311942e-05, -9.46458385e-07,  1.12127585e-04,  5.24599636e-06,\n",
              "        -3.21046209e-05,  3.07385053e-05,  2.60379602e-06, -6.51698656e-06,\n",
              "        -5.70847697e-05, -2.57752890e-05, -1.85632666e-06,  1.20693066e-05,\n",
              "         4.41941811e-05,  5.27409939e-05, -6.13323664e-06,  4.66659549e-05,\n",
              "        -3.96423414e-02, -5.65765891e-03,  3.84638086e-02, -3.04253791e-02,\n",
              "         2.15299847e-03, -2.71945596e-02,  4.38010879e-02,  2.98216678e-02,\n",
              "        -1.01148095e-02, -3.46007803e-03, -4.75648642e-02, -3.52091063e-03,\n",
              "        -6.27968907e-02,  1.50049888e-02,  2.51152739e-02, -3.52737829e-02,\n",
              "        -2.33082892e-03, -1.02762412e-02,  1.96823943e-02, -2.10875291e-02,\n",
              "         3.02958004e-02, -1.81250870e-02,  2.40815282e-02,  2.27841474e-02,\n",
              "        -3.79781462e-02, -3.31908166e-02,  2.62915753e-02, -2.88937110e-02,\n",
              "        -8.83273594e-03,  5.74676227e-03,  3.22655514e-02, -8.29748064e-03,\n",
              "        -1.64671503e-02,  3.24078500e-02, -5.03643453e-02,  4.34697121e-02,\n",
              "         5.22051007e-03, -3.75282690e-02,  3.25642969e-03,  1.52002368e-03,\n",
              "         4.18215878e-02,  1.62168555e-02, -5.97361010e-04, -1.67422388e-02,\n",
              "         1.56131713e-03, -5.88367358e-02,  2.65284106e-02, -5.17579019e-02,\n",
              "         4.44187671e-02, -2.62404401e-02, -8.57787766e-03, -5.26898168e-03,\n",
              "        -9.70636867e-03,  3.66565189e-04, -5.54528646e-02, -1.35940611e-02,\n",
              "        -3.64447641e-03,  1.22604007e-03, -3.13955992e-02, -5.50706945e-02,\n",
              "         7.52208102e-03,  6.62839040e-04,  3.68181169e-02,  2.26213131e-02,\n",
              "         1.04078930e-02, -1.74411386e-02,  2.97400448e-02,  3.95768397e-02,\n",
              "        -2.42556203e-02,  8.17959663e-03,  2.64215074e-03, -3.59904990e-02,\n",
              "        -5.83446864e-03, -7.17968587e-03,  1.24882329e-02,  4.09964249e-02,\n",
              "         3.70751843e-02, -1.77916810e-02,  5.64424880e-03, -2.84320787e-02,\n",
              "        -1.59197152e-02, -7.33741140e-03,  8.85767303e-03,  4.97913957e-02,\n",
              "         4.00929749e-02, -8.19341466e-03,  4.89902869e-02,  3.32754701e-02,\n",
              "        -1.21586649e-02, -1.26602510e-02,  6.26361668e-02, -4.41546887e-02,\n",
              "         8.40449985e-03,  7.54697388e-03,  7.53984740e-03, -2.88688540e-02,\n",
              "        -5.13420478e-02,  5.09834150e-03, -2.37490796e-02,  3.19544189e-02,\n",
              "         1.60293514e-03, -4.92744260e-02, -6.94755232e-03, -2.03128532e-02,\n",
              "        -2.36845389e-02, -4.91704196e-02, -1.21369567e-02,  7.19241798e-05,\n",
              "         2.29677390e-02,  1.61646865e-04,  1.63336087e-03, -1.01489387e-03,\n",
              "        -3.61233950e-02,  1.51932705e-02, -2.57147942e-04,  9.63311922e-03,\n",
              "        -2.62156855e-02,  2.44358438e-03,  9.70501453e-03, -1.03199901e-02,\n",
              "         3.78324464e-02,  1.38822142e-02,  3.14130518e-03,  1.39819495e-02,\n",
              "        -1.28208278e-02, -1.94533113e-02, -1.78198069e-02,  3.35953720e-02,\n",
              "        -6.10282223e-05, -9.96694689e-06,  2.81926023e-05,  1.32337213e-04,\n",
              "        -3.02834451e-05,  1.34953916e-05,  9.81515768e-06,  1.00539637e-05,\n",
              "         6.85100986e-06, -3.52900242e-05,  9.11824827e-06, -5.04901109e-05,\n",
              "        -1.03115644e-05,  4.50585212e-05,  4.02315745e-05,  6.53286406e-06,\n",
              "         9.60419857e-06,  2.68058629e-05, -4.39894720e-05, -3.47000823e-05,\n",
              "        -5.89484371e-05, -2.84132639e-05,  3.63160598e-06,  1.09541515e-05,\n",
              "         1.32519044e-05,  2.64790233e-05,  1.18186254e-05,  1.92408970e-05,\n",
              "         3.06670336e-05, -2.77847830e-05, -1.60963573e-05,  5.69152835e-05,\n",
              "         2.88019801e-05,  2.65772578e-05, -4.81010284e-05, -6.56315387e-05,\n",
              "         1.83250631e-05,  5.86212336e-05, -2.42181777e-05,  8.19960496e-06,\n",
              "        -5.40298879e-06,  3.48814356e-05, -2.50867306e-05, -3.04958448e-05,\n",
              "        -2.74439626e-05,  1.99605547e-05,  2.00463655e-05, -7.06988576e-05,\n",
              "        -9.07484537e-06, -8.83280736e-05, -5.24317402e-05,  6.13575248e-05,\n",
              "         2.02769024e-05,  1.00116595e-05, -8.56454280e-05, -2.64992050e-05,\n",
              "        -1.54757363e-05,  1.96653286e-06, -5.18316810e-05, -4.39892829e-05,\n",
              "        -1.77941693e-05,  1.78793634e-05,  5.38993390e-06, -2.16622502e-05,\n",
              "        -1.57131835e-05, -3.18722232e-05,  4.28691783e-05, -2.56129829e-06,\n",
              "        -2.24184641e-05, -2.36870183e-05,  1.15592629e-05, -6.59197394e-05,\n",
              "        -3.91865433e-06,  2.57799893e-05, -3.47056812e-05, -7.64509823e-05,\n",
              "         2.46245545e-05,  1.99554215e-05,  8.62864817e-06,  2.29625730e-05,\n",
              "        -1.00494699e-05,  3.97304029e-06,  4.78099537e-05,  9.39053862e-05,\n",
              "        -4.13470079e-05, -4.42040473e-05, -5.61481866e-05,  2.24649884e-05,\n",
              "        -2.33474857e-05, -1.22102228e-05, -4.31570261e-05, -6.96039933e-05,\n",
              "         1.44535416e-05,  3.48848589e-05,  1.55887501e-05,  5.13419218e-05,\n",
              "         8.32287060e-06,  1.89604016e-05, -5.34989231e-05,  1.59974334e-05,\n",
              "         1.67435555e-05, -1.19562196e-06,  2.12854429e-05, -4.94738888e-05,\n",
              "         9.57716293e-06, -1.16132163e-04, -8.41155452e-06, -2.98196701e-05,\n",
              "        -2.73064070e-05,  2.38575631e-05, -3.46984234e-05,  1.30767148e-05,\n",
              "        -3.74936753e-05,  3.84252417e-06,  9.33163028e-05, -5.32031572e-06,\n",
              "        -3.63908202e-06,  1.75336500e-05,  2.17418165e-05, -1.42260305e-05,\n",
              "        -2.44282928e-05, -1.50880114e-05, -2.27969576e-05,  1.62852320e-05,\n",
              "         2.07352059e-05,  3.51844647e-05,  1.13220703e-05,  3.86060747e-05],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(128, 10000), dtype=float32, numpy=\n",
              " array([[-2.2136683e-03, -3.0521704e-03, -1.3861044e-03, ...,\n",
              "          2.2453858e-06,  2.2448494e-06,  2.2464287e-06],\n",
              "        [-1.6136501e-04,  3.1252997e-04,  1.3628686e-03, ...,\n",
              "         -1.3164829e-06, -1.3170138e-06, -1.3186660e-06],\n",
              "        [-5.8814691e-04, -2.7936272e-05, -5.9345912e-04, ...,\n",
              "          8.9910566e-07,  9.0088201e-07,  9.0000401e-07],\n",
              "        ...,\n",
              "        [ 2.0753066e-03,  2.6749447e-03,  1.4803020e-03, ...,\n",
              "         -4.0003738e-06, -3.9988868e-06, -4.0009304e-06],\n",
              "        [ 2.9454096e-03,  3.0650669e-03,  2.5771032e-03, ...,\n",
              "         -5.4220136e-06, -5.4215725e-06, -5.4230468e-06],\n",
              "        [-1.7190180e-03, -3.5369024e-03, -2.0405173e-03, ...,\n",
              "          2.9443706e-06,  2.9430623e-06,  2.9454238e-06]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(10000,), dtype=float32, numpy=\n",
              " array([-0.79799825, -1.0313314 , -1.0313313 , ...,  0.0019997 ,\n",
              "         0.00199942,  0.0020004 ], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC1kSg8SPylY"
      },
      "source": [
        "*5.Apply the optimizer to the variables/gradients tuple.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3cLs3ARPvsw"
      },
      "source": [
        "# Create the training TensorFlow Operation through our optimizer\n",
        "train_op = optimizer.apply_gradients(zip(grads, tvars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ5HdY7nP15h"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBN9NGvoP4Sx"
      },
      "source": [
        "class PTBModel(object):\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        ######################################\n",
        "        # Setting parameters for ease of use #\n",
        "        ######################################\n",
        "        self.batch_size = batch_size\n",
        "        self.num_steps = num_steps\n",
        "        self.hidden_size_l1 = hidden_size_l1\n",
        "        self.hidden_size_l2 = hidden_size_l2\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embeding_vector_size = embeding_vector_size\n",
        "        # Create a variable for the learning rate\n",
        "        self._lr = 1.0\n",
        "        \n",
        "        ###############################################################################\n",
        "        # Initializing the model using keras Sequential API  #\n",
        "        ###############################################################################\n",
        "        \n",
        "        self._model = tf.keras.models.Sequential()\n",
        "        \n",
        "        ####################################################################\n",
        "        # Creating the word embeddings layer and adding it to the sequence #\n",
        "        ####################################################################\n",
        "        with tf.device(\"/cpu:0\"):\n",
        "            # Create the embeddings for our input data. Size is hidden size.\n",
        "            self._embedding_layer = tf.keras.layers.Embedding(self.vocab_size, self.embeding_vector_size,batch_input_shape=(self.batch_size, self.num_steps),trainable=True,name=\"embedding_vocab\")  #[10000x200]\n",
        "            self._model.add(self._embedding_layer)\n",
        "            \n",
        "\n",
        "        ##########################################################################\n",
        "        # Creating the LSTM cell structure and connect it with the RNN structure #\n",
        "        ##########################################################################\n",
        "        # Create the LSTM Cells. \n",
        "        # This creates only the structure for the LSTM and has to be associated with a RNN unit still.\n",
        "        # The argument  of LSTMCell is size of hidden layer, that is, the number of hidden units of the LSTM (inside A). \n",
        "        # LSTM cell processes one word at a time and computes probabilities of the possible continuations of the sentence.\n",
        "        lstm_cell_l1 = tf.keras.layers.LSTMCell(hidden_size_l1)\n",
        "        lstm_cell_l2 = tf.keras.layers.LSTMCell(hidden_size_l2)\n",
        "        \n",
        "\n",
        "        \n",
        "        # By taking in the LSTM cells as parameters, the StackedRNNCells function junctions the LSTM units to the RNN units.\n",
        "        # RNN cell composed sequentially of stacked simple cells.\n",
        "        stacked_lstm = tf.keras.layers.StackedRNNCells([lstm_cell_l1, lstm_cell_l2])\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        ############################################\n",
        "        # Creating the input structure for our RNN #\n",
        "        ############################################\n",
        "        # Input structure is 20x[30x200]\n",
        "        # Considering each word is represended by a 200 dimentional vector, and we have 30 batchs, we create 30 word-vectors of size [30xx2000]\n",
        "        # The input structure is fed from the embeddings, which are filled in by the input data\n",
        "        # Feeding a batch of b sentences to a RNN:\n",
        "        # In step 1,  first word of each of the b sentences (in a batch) is input in parallel.  \n",
        "        # In step 2,  second word of each of the b sentences is input in parallel. \n",
        "        # The parallelism is only for efficiency.  \n",
        "        # Each sentence in a batch is handled in parallel, but the network sees one word of a sentence at a time and does the computations accordingly. \n",
        "        # All the computations involving the words of all sentences in a batch at a given time step are done in parallel. \n",
        "\n",
        "        ########################################################################################################\n",
        "        # Instantiating our RNN model and setting stateful to True to feed forward the state to the next layer #\n",
        "        ########################################################################################################\n",
        "        \n",
        "        self._RNNlayer  =  tf.keras.layers.RNN(stacked_lstm,[batch_size, num_steps],return_state=False,stateful=True,trainable=True)\n",
        "        \n",
        "        # Define the initial state, i.e., the model state for the very first data point\n",
        "        # It initialize the state of the LSTM memory. The memory state of the network is initialized with a vector of zeros and gets updated after reading each word.\n",
        "        self._initial_state = tf.Variable(tf.zeros([batch_size,embeding_vector_size]),trainable=False)\n",
        "        self._RNNlayer.inital_state = self._initial_state\n",
        "    \n",
        "        ############################################\n",
        "        # Adding RNN layer to keras sequential API #\n",
        "        ############################################        \n",
        "        self._model.add(self._RNNlayer)\n",
        "        \n",
        "        #self._model.add(tf.keras.layers.LSTM(hidden_size_l1,return_sequences=True,stateful=True))\n",
        "        #self._model.add(tf.keras.layers.LSTM(hidden_size_l2,return_sequences=True))\n",
        "        \n",
        "        \n",
        "        ####################################################################################################\n",
        "        # Instantiating a Dense layer that connects the output to the vocab_size  and adding layer to model#\n",
        "        ####################################################################################################\n",
        "        self._dense = tf.keras.layers.Dense(self.vocab_size)\n",
        "        self._model.add(self._dense)\n",
        " \n",
        "        \n",
        "        ####################################################################################################\n",
        "        # Adding softmax activation layer and deriving probability to each class and adding layer to model #\n",
        "        ####################################################################################################\n",
        "        self._activation = tf.keras.layers.Activation('softmax')\n",
        "        self._model.add(self._activation)\n",
        "\n",
        "        ##########################################################\n",
        "        # Instantiating the stochastic gradient decent optimizer #\n",
        "        ########################################################## \n",
        "        self._optimizer = tf.keras.optimizers.SGD(lr=self._lr, clipnorm=max_grad_norm)\n",
        "        \n",
        "        \n",
        "        ##############################################################################\n",
        "        # Compiling and summarizing the model stacked using the keras sequential API #\n",
        "        ##############################################################################\n",
        "        self._model.compile(loss=self.crossentropy, optimizer=self._optimizer)\n",
        "        self._model.summary()\n",
        "\n",
        "\n",
        "    def crossentropy(self,y_true, y_pred):\n",
        "        return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "    def train_batch(self,_input_data,_targets):\n",
        "        #################################################\n",
        "        # Creating the Training Operation for our Model #\n",
        "        #################################################\n",
        "        # Create a variable for the learning rate\n",
        "        self._lr = tf.Variable(0.0, trainable=False)\n",
        "        # Get all TensorFlow variables marked as \"trainable\" (i.e. all of them except _lr, which we just created)\n",
        "        tvars = self._model.trainable_variables\n",
        "        # Define the gradient clipping threshold\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass.\n",
        "            output_words_prob = self._model(_input_data)\n",
        "            # Loss value for this batch.\n",
        "            loss  = self.crossentropy(_targets, output_words_prob)\n",
        "            # average across batch and reduce sum\n",
        "            cost = tf.reduce_sum(loss/ self.batch_size)\n",
        "        # Get gradients of loss wrt the trainable variables.\n",
        "        grad_t_list = tape.gradient(cost, tvars)\n",
        "        # Define the gradient clipping threshold\n",
        "        grads, _ = tf.clip_by_global_norm(grad_t_list, max_grad_norm)\n",
        "        # Create the training TensorFlow Operation through our optimizer\n",
        "        train_op = self._optimizer.apply_gradients(zip(grads, tvars))\n",
        "        return cost\n",
        "        \n",
        "    def test_batch(self,_input_data,_targets):\n",
        "        #################################################\n",
        "        # Creating the Testing Operation for our Model #\n",
        "        #################################################\n",
        "        output_words_prob = self._model(_input_data)\n",
        "        loss  = self.crossentropy(_targets, output_words_prob)\n",
        "        # average across batch and reduce sum\n",
        "        cost = tf.reduce_sum(loss/ self.batch_size)\n",
        "\n",
        "        return cost\n",
        "    @classmethod\n",
        "    def instance(cls) : \n",
        "        return PTBModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYM_yFcDP9wK"
      },
      "source": [
        "\n",
        "########################################################################################################################\n",
        "# run_one_epoch takes as parameters  the model instance, the data to be fed, training or testing mode and verbose info #\n",
        "########################################################################################################################\n",
        "def run_one_epoch(m, data,is_training=True,verbose=False):\n",
        "\n",
        "    #Define the epoch size based on the length of the data, batch size and the number of steps\n",
        "    epoch_size = ((len(data) // m.batch_size) - 1) // m.num_steps\n",
        "    start_time = time.time()\n",
        "    costs = 0.\n",
        "    iters = 0\n",
        "    \n",
        "    m._model.reset_states()\n",
        "    \n",
        "    #For each step and data point\n",
        "    for step, (x, y) in enumerate(reader.ptb_iterator(data, m.batch_size, m.num_steps)):\n",
        "        \n",
        "        #Evaluate and return cost, state by running cost, final_state and the function passed as parameter\n",
        "        #y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
        "        if is_training : \n",
        "            loss=  m.train_batch(x, y)\n",
        "        else :\n",
        "            loss = m.test_batch(x, y)\n",
        "                                   \n",
        "\n",
        "        #Add returned cost to costs (which keeps track of the total costs for this epoch)\n",
        "        costs += loss\n",
        "        \n",
        "        #Add number of steps to iteration counter\n",
        "        iters += m.num_steps\n",
        "\n",
        "        if verbose and step % (epoch_size // 10) == 10:\n",
        "            print(\"Itr %d of %d, perplexity: %.3f speed: %.0f wps\" % (step , epoch_size, np.exp(costs / iters), iters * m.batch_size / (time.time() - start_time)))\n",
        "        \n",
        "\n",
        "\n",
        "    # Returns the Perplexity rating for us to keep track of how the model is evolving\n",
        "    return np.exp(costs / iters)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T-tf1kYQAXF"
      },
      "source": [
        "# Reads the data and separates it into training data, validation data and testing data\n",
        "raw_data = reader.ptb_raw_data(data_dir)\n",
        "train_data, valid_data, test_data, _, _ = raw_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s6_R9oDmQA3Y",
        "outputId": "62ae1e23-f954-432d-f080-752a0395d57a"
      },
      "source": [
        "# Instantiates the PTBModel class\n",
        "m=PTBModel.instance()   \n",
        "K = tf.keras.backend \n",
        "for i in range(max_epoch):\n",
        "    # Define the decay for this epoch\n",
        "    lr_decay = decay ** max(i - max_epoch_decay_lr, 0.0)\n",
        "    dcr = learning_rate * lr_decay\n",
        "    m._lr = dcr\n",
        "    K.set_value(m._model.optimizer.learning_rate,m._lr)\n",
        "    print(\"Epoch %d : Learning rate: %.3f\" % (i + 1, m._model.optimizer.learning_rate))\n",
        "    # Run the loop for this epoch in the training mode\n",
        "    train_perplexity = run_one_epoch(m, train_data,is_training=True,verbose=True)\n",
        "    print(\"Epoch %d : Train Perplexity: %.3f\" % (i + 1, train_perplexity))\n",
        "        \n",
        "    # Run the loop for this epoch in the validation mode\n",
        "    valid_perplexity = run_one_epoch(m, valid_data,is_training=False,verbose=False)\n",
        "    print(\"Epoch %d : Valid Perplexity: %.3f\" % (i + 1, valid_perplexity))\n",
        "    \n",
        "# Run the loop in the testing mode to see how effective was our training\n",
        "test_perplexity = run_one_epoch(m, test_data,is_training=False,verbose=False)\n",
        "print(\"Test Perplexity: %.3f\" % test_perplexity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_vocab (Embedding)  (30, 20, 200)             2000000   \n",
            "_________________________________________________________________\n",
            "rnn_1 (RNN)                  (30, 20, 128)             671088    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (30, 20, 10000)           1290000   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (30, 20, 10000)           0         \n",
            "=================================================================\n",
            "Total params: 3,961,088\n",
            "Trainable params: 3,955,088\n",
            "Non-trainable params: 6,000\n",
            "_________________________________________________________________\n",
            "Epoch 1 : Learning rate: 1.000\n",
            "Itr 10 of 1549, perplexity: 4915.144 speed: 1057 wps\n",
            "Itr 164 of 1549, perplexity: 1087.330 speed: 1095 wps\n",
            "Itr 318 of 1549, perplexity: 846.870 speed: 1097 wps\n",
            "Itr 472 of 1549, perplexity: 703.999 speed: 1099 wps\n",
            "Itr 626 of 1549, perplexity: 598.755 speed: 1098 wps\n",
            "Itr 780 of 1549, perplexity: 531.677 speed: 1098 wps\n",
            "Itr 934 of 1549, perplexity: 479.774 speed: 1099 wps\n",
            "Itr 1088 of 1549, perplexity: 440.712 speed: 1101 wps\n",
            "Itr 1242 of 1549, perplexity: 410.559 speed: 1101 wps\n",
            "Itr 1396 of 1549, perplexity: 382.541 speed: 1101 wps\n",
            "Epoch 1 : Train Perplexity: 360.403\n",
            "Epoch 1 : Valid Perplexity: 212.429\n",
            "Epoch 2 : Learning rate: 1.000\n",
            "Itr 10 of 1549, perplexity: 240.880 speed: 1098 wps\n",
            "Itr 164 of 1549, perplexity: 212.395 speed: 1098 wps\n",
            "Itr 318 of 1549, perplexity: 203.646 speed: 1089 wps\n",
            "Itr 472 of 1549, perplexity: 195.786 speed: 1086 wps\n",
            "Itr 626 of 1549, perplexity: 186.878 speed: 1087 wps\n",
            "Itr 780 of 1549, perplexity: 183.179 speed: 1087 wps\n",
            "Itr 934 of 1549, perplexity: 179.025 speed: 1088 wps\n",
            "Itr 1088 of 1549, perplexity: 175.576 speed: 1089 wps\n",
            "Itr 1242 of 1549, perplexity: 173.236 speed: 1090 wps\n",
            "Itr 1396 of 1549, perplexity: 169.130 speed: 1089 wps\n",
            "Epoch 2 : Train Perplexity: 166.319\n",
            "Epoch 2 : Valid Perplexity: 164.109\n",
            "Epoch 3 : Learning rate: 1.000\n",
            "Itr 10 of 1549, perplexity: 166.485 speed: 1088 wps\n",
            "Itr 164 of 1549, perplexity: 148.772 speed: 1090 wps\n",
            "Itr 318 of 1549, perplexity: 145.346 speed: 1089 wps\n",
            "Itr 472 of 1549, perplexity: 140.956 speed: 1090 wps\n",
            "Itr 626 of 1549, perplexity: 135.740 speed: 1091 wps\n",
            "Itr 780 of 1549, perplexity: 134.636 speed: 1095 wps\n",
            "Itr 934 of 1549, perplexity: 132.808 speed: 1096 wps\n",
            "Itr 1088 of 1549, perplexity: 131.324 speed: 1095 wps\n",
            "Itr 1242 of 1549, perplexity: 130.526 speed: 1096 wps\n",
            "Itr 1396 of 1549, perplexity: 128.237 speed: 1097 wps\n",
            "Epoch 3 : Train Perplexity: 126.964\n",
            "Epoch 3 : Valid Perplexity: 146.519\n",
            "Epoch 4 : Learning rate: 1.000\n",
            "Itr 10 of 1549, perplexity: 133.545 speed: 1085 wps\n",
            "Itr 164 of 1549, perplexity: 121.947 speed: 1092 wps\n",
            "Itr 318 of 1549, perplexity: 119.883 speed: 1094 wps\n",
            "Itr 472 of 1549, perplexity: 116.434 speed: 1093 wps\n",
            "Itr 626 of 1549, perplexity: 112.553 speed: 1090 wps\n",
            "Itr 780 of 1549, perplexity: 112.070 speed: 1092 wps\n",
            "Itr 934 of 1549, perplexity: 110.913 speed: 1090 wps\n",
            "Itr 1088 of 1549, perplexity: 110.006 speed: 1091 wps\n",
            "Itr 1242 of 1549, perplexity: 109.612 speed: 1091 wps\n",
            "Itr 1396 of 1549, perplexity: 107.973 speed: 1091 wps\n",
            "Epoch 4 : Train Perplexity: 107.192\n",
            "Epoch 4 : Valid Perplexity: 139.832\n",
            "Epoch 5 : Learning rate: 1.000\n",
            "Itr 10 of 1549, perplexity: 115.376 speed: 1075 wps\n",
            "Itr 164 of 1549, perplexity: 106.255 speed: 1090 wps\n",
            "Itr 318 of 1549, perplexity: 104.876 speed: 1090 wps\n",
            "Itr 472 of 1549, perplexity: 101.926 speed: 1091 wps\n",
            "Itr 626 of 1549, perplexity: 98.605 speed: 1094 wps\n",
            "Itr 780 of 1549, perplexity: 98.390 speed: 1094 wps\n",
            "Itr 934 of 1549, perplexity: 97.539 speed: 1095 wps\n",
            "Itr 1088 of 1549, perplexity: 96.954 speed: 1096 wps\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-4f91aeb0ef44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch %d : Learning rate: %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Run the loop for this epoch in the training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch %d : Train Perplexity: %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_perplexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-c07b97c58e82>\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(m, data, is_training, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_training\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-ce16a0a5575f>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, _input_data, _targets)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;31m# Forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0moutput_words_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0;31m# Loss value for this batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mloss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_words_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    370\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 386\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow_lengths\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow_lengths\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         zero_output_for_mask=self.zero_output_for_mask)\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4359\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4361\u001b[0;31m           **while_loop_kwargs)\n\u001b[0m\u001b[1;32m   4362\u001b[0m       \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2733\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2734\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2735\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   4343\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4344\u001b[0m         output, new_states = step_function(current_input,\n\u001b[0;32m-> 4345\u001b[0;31m                                            tuple(states) + tuple(constants))\n\u001b[0m\u001b[1;32m   4346\u001b[0m         \u001b[0mflat_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4347\u001b[0m         \u001b[0mflat_new_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    791\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_tf_rnn_cell\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m           \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, constants, training, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m                                       constants=constants, **kwargs)\n\u001b[1;32m    159\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m       \u001b[0mnew_nested_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m   2468\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdp_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m       \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m       \u001b[0mz\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1829\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1831\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1832\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   3253\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3254\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 3255\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   3256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5619\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5620\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5621\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5622\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5623\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}